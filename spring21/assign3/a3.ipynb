{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting Fake News"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trevor Grabham\n",
    "#### 301281720"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First step, imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next we read in the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty lists to hold our data\n",
    "title = []\n",
    "body = []\n",
    "combined = []\n",
    "y = []\n",
    "# read in all the real articles (have to do this seperately because they are in different folders)\n",
    "for i in range(1500):\n",
    "    with open('fake-real-news-1500/fake-real-news/train/real/real'+str(i)+'.txt',encoding=\"utf-8\") as f:\n",
    "        # the first line is always the title\n",
    "        title.append(f.readline().strip())\n",
    "        # this just reads the remainder of the file\n",
    "        body.append(f.read())\n",
    "        # combine it all back into one so that we can use all of the data later on \n",
    "        combined.append(title[i] + '\\n' + body[i])\n",
    "        # the correct value for our ML algorithms\n",
    "        y.append(1)\n",
    "# read in the fake news\n",
    "for i in range(1500):\n",
    "    with open('fake-real-news-1500/fake-real-news/train/fake/fake'+str(i)+'.txt',encoding=\"utf-8\") as f:\n",
    "        title.append(f.readline().strip())\n",
    "        body.append(f.read()) \n",
    "        combined.append(title[i] + '\\n' +  body[i])\n",
    "        y.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### now to turn the data into a more readable form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zip up the data so that we can get them in the proper form for the DataFrame\n",
    "#df = pd.DataFrame(list(zip(title, body, combined, y)), columns=['title','body','combined','y'])\n",
    "#df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We now need to turn the data into a usable form for the algorithms. We turn to nltk for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to hold all of our parsed sentences\n",
    "#dictionary = []\n",
    "#stemmer = PorterStemmer()\n",
    "#for i in range(len(df)):\n",
    "    # get rid of any characters that aren't alphabetic\n",
    "#    words = re.sub('[^a-zA-z]', ' ', df['combined'][i])\n",
    "    # make all of our words lower case so that we don't have to worry about case sensitivity later\n",
    "#    words = words.lower()\n",
    "    # split up all of the words around the spaces\n",
    "#    words = words.split()\n",
    "    # apply the stemmer to the words after we filter out the words in the stop words dictionary\n",
    "#    words = [stemmer.stem(word) for word in words if not word in stopwords.words('english')]\n",
    "    # join all of our words back together again\n",
    "#    words = ' '.join(words)\n",
    "    # add the list of words to our dictionary\n",
    "#    dictionary.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to hold all of our parsed sentences\n",
    "dictionary_title = []\n",
    "stemmer = PorterStemmer()\n",
    "for i in range(len(title)):\n",
    "    # get rid of any characters that aren't alphabetic\n",
    "    words = re.sub('[^a-zA-z]', ' ', title[i])\n",
    "    # make all of our words lower case so that we don't have to worry about case sensitivity later\n",
    "    words = words.lower()\n",
    "    # split up all of the words around the spaces\n",
    "    words = words.split()\n",
    "    # apply the stemmer to the words after we filter out the words in the stop words dictionary\n",
    "    words = [stemmer.stem(word) for word in words if not word in stopwords.words('english')]\n",
    "    # join all of our words back together again\n",
    "    words = ' '.join(words)\n",
    "    # add the list of words to our dictionary\n",
    "    dictionary_title.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to hold all of our parsed sentences\n",
    "#dictionary_body = []\n",
    "#stemmer = PorterStemmer()\n",
    "#for i in range(len(title)):\n",
    "    # get rid of any characters that aren't alphabetic\n",
    "#    words = re.sub('[^a-zA-z]', ' ', title[i])\n",
    "    # make all of our words lower case so that we don't have to worry about case sensitivity later\n",
    "#    words = words.lower()\n",
    "    # split up all of the words around the spaces\n",
    "#    words = words.split()\n",
    "    # apply the stemmer to the words after we filter out the words in the stop words dictionary\n",
    "#    words = [stemmer.stem(word) for word in words if not word in stopwords.words('english')]\n",
    "    # join all of our words back together again\n",
    "#    words = ' '.join(words)\n",
    "    # add the list of words to our dictionary\n",
    "#    dictionary_body.append(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### if we want to play around with some of the parameters later, we can come back to the creation of our dictionary and only include the titles or the bodies, to see if that makes any difference, or if we have extrenuous data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### now to apply the count vectorizer to get more meaningful data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "countVect = CountVectorizer(max_features=5000,ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create our x data out of the dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_title = countVect.fit_transform(dictionary_title).toarray()\n",
    "#x_body = countVect.fit_transform(dictionary_body).toarray()\n",
    "#x = countVect.fit_transform(dictionary).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create our neural net classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = MLPClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cross validate to check how we are doing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross_val_score(net,x_title,y,cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross_val_score(net,x_body,y,cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross_val_score(net,x,y,cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, we are doing much better with the title and the body data seperated, it would seem like we have too much data to play with when combining them all together, we are not getting interesting enough features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### lets give it more time to fine tune the weights, and lets give it an extra hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#net = MLPClassifier(max_iter=500,solver='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross_val_score(net,x_title,y,cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### not too much of a change here, lets see if warm start will help at all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#net = MLPClassifier(max_iter=1000,solver='sgd', hidden_layer_sizes=(100,100),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross_val_score(net,x_title,y,cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### still not too much of a change, lets see if adding another hidden layer will help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#net = MLPClassifier(max_iter=1000,solver='sgd', hidden_layer_sizes=(100,100,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross_val_score(net,x_title,y,cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### about the same as before, lets up the size of the hidden layer and see if a different activation fucntion will help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#net = MLPClassifier(max_iter=500,solver='lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross_val_score(net,x_title,y,cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\treva\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\treva\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\treva\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 1027, in fit\n",
      "    return self._fit(X, y, incremental=(self.warm_start and\n",
      "  File \"c:\\users\\treva\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 375, in _fit\n",
      "    self._fit_lbfgs(X, y, activations, deltas, coef_grads,\n",
      "  File \"c:\\users\\treva\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 461, in _fit_lbfgs\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"c:\\users\\treva\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\scipy\\optimize\\_minimize.py\", line 609, in minimize\n",
      "    return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"c:\\users\\treva\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\scipy\\optimize\\lbfgsb.py\", line 322, in _minimize_lbfgsb\n",
      "    wa = zeros(2*m*n + 5*n + 11*m*m + 8*m, float64)\n",
      "MemoryError: Unable to allocate 716. MiB for an array with shape (93788705,) and data type float64\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\users\\treva\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\treva\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\treva\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 1027, in fit\n",
      "    return self._fit(X, y, incremental=(self.warm_start and\n",
      "  File \"c:\\users\\treva\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 375, in _fit\n",
      "    self._fit_lbfgs(X, y, activations, deltas, coef_grads,\n",
      "  File \"c:\\users\\treva\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 461, in _fit_lbfgs\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"c:\\users\\treva\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\scipy\\optimize\\_minimize.py\", line 609, in minimize\n",
      "    return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"c:\\users\\treva\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\scipy\\optimize\\lbfgsb.py\", line 322, in _minimize_lbfgsb\n",
      "    wa = zeros(2*m*n + 5*n + 11*m*m + 8*m, float64)\n",
      "MemoryError: Unable to allocate 716. MiB for an array with shape (93788705,) and data type float64\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\users\\treva\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\treva\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\treva\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 1027, in fit\n",
      "    return self._fit(X, y, incremental=(self.warm_start and\n",
      "  File \"c:\\users\\treva\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 375, in _fit\n",
      "    self._fit_lbfgs(X, y, activations, deltas, coef_grads,\n",
      "  File \"c:\\users\\treva\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 461, in _fit_lbfgs\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"c:\\users\\treva\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\scipy\\optimize\\_minimize.py\", line 609, in minimize\n",
      "    return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"c:\\users\\treva\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\scipy\\optimize\\lbfgsb.py\", line 322, in _minimize_lbfgsb\n",
      "    wa = zeros(2*m*n + 5*n + 11*m*m + 8*m, float64)\n",
      "MemoryError: Unable to allocate 716. MiB for an array with shape (93788705,) and data type float64\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\users\\treva\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\treva\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\treva\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 1027, in fit\n",
      "    return self._fit(X, y, incremental=(self.warm_start and\n",
      "  File \"c:\\users\\treva\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 375, in _fit\n",
      "    self._fit_lbfgs(X, y, activations, deltas, coef_grads,\n",
      "  File \"c:\\users\\treva\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 461, in _fit_lbfgs\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"c:\\users\\treva\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\scipy\\optimize\\_minimize.py\", line 609, in minimize\n",
      "    return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"c:\\users\\treva\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\scipy\\optimize\\lbfgsb.py\", line 322, in _minimize_lbfgsb\n",
      "    wa = zeros(2*m*n + 5*n + 11*m*m + 8*m, float64)\n",
      "MemoryError: Unable to allocate 716. MiB for an array with shape (93788705,) and data type float64\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\users\\treva\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\treva\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\treva\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 1027, in fit\n",
      "    return self._fit(X, y, incremental=(self.warm_start and\n",
      "  File \"c:\\users\\treva\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 375, in _fit\n",
      "    self._fit_lbfgs(X, y, activations, deltas, coef_grads,\n",
      "  File \"c:\\users\\treva\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 461, in _fit_lbfgs\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"c:\\users\\treva\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\scipy\\optimize\\_minimize.py\", line 609, in minimize\n",
      "    return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"c:\\users\\treva\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\scipy\\optimize\\lbfgsb.py\", line 322, in _minimize_lbfgsb\n",
      "    wa = zeros(2*m*n + 5*n + 11*m*m + 8*m, float64)\n",
      "MemoryError: Unable to allocate 716. MiB for an array with shape (93788705,) and data type float64\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\treva\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\treva\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\treva\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 1027, in fit\n",
      "    return self._fit(X, y, incremental=(self.warm_start and\n",
      "  File \"c:\\users\\treva\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 375, in _fit\n",
      "    self._fit_lbfgs(X, y, activations, deltas, coef_grads,\n",
      "  File \"c:\\users\\treva\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 461, in _fit_lbfgs\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"c:\\users\\treva\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\scipy\\optimize\\_minimize.py\", line 609, in minimize\n",
      "    return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"c:\\users\\treva\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\scipy\\optimize\\lbfgsb.py\", line 322, in _minimize_lbfgsb\n",
      "    wa = zeros(2*m*n + 5*n + 11*m*m + 8*m, float64)\n",
      "MemoryError: Unable to allocate 716. MiB for an array with shape (93788705,) and data type float64\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\users\\treva\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\treva\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\treva\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 1027, in fit\n",
      "    return self._fit(X, y, incremental=(self.warm_start and\n",
      "  File \"c:\\users\\treva\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 375, in _fit\n",
      "    self._fit_lbfgs(X, y, activations, deltas, coef_grads,\n",
      "  File \"c:\\users\\treva\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 461, in _fit_lbfgs\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"c:\\users\\treva\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\scipy\\optimize\\_minimize.py\", line 609, in minimize\n",
      "    return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"c:\\users\\treva\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\scipy\\optimize\\lbfgsb.py\", line 322, in _minimize_lbfgsb\n",
      "    wa = zeros(2*m*n + 5*n + 11*m*m + 8*m, float64)\n",
      "MemoryError: Unable to allocate 716. MiB for an array with shape (93788705,) and data type float64\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\users\\treva\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\treva\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\treva\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 1027, in fit\n",
      "    return self._fit(X, y, incremental=(self.warm_start and\n",
      "  File \"c:\\users\\treva\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 375, in _fit\n",
      "    self._fit_lbfgs(X, y, activations, deltas, coef_grads,\n",
      "  File \"c:\\users\\treva\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 461, in _fit_lbfgs\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"c:\\users\\treva\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\scipy\\optimize\\_minimize.py\", line 609, in minimize\n",
      "    return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"c:\\users\\treva\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\scipy\\optimize\\lbfgsb.py\", line 322, in _minimize_lbfgsb\n",
      "    wa = zeros(2*m*n + 5*n + 11*m*m + 8*m, float64)\n",
      "MemoryError: Unable to allocate 716. MiB for an array with shape (93788705,) and data type float64\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\users\\treva\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\treva\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\treva\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 1027, in fit\n",
      "    return self._fit(X, y, incremental=(self.warm_start and\n",
      "  File \"c:\\users\\treva\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 375, in _fit\n",
      "    self._fit_lbfgs(X, y, activations, deltas, coef_grads,\n",
      "  File \"c:\\users\\treva\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 461, in _fit_lbfgs\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"c:\\users\\treva\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\scipy\\optimize\\_minimize.py\", line 609, in minimize\n",
      "    return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"c:\\users\\treva\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\scipy\\optimize\\lbfgsb.py\", line 322, in _minimize_lbfgsb\n",
      "    wa = zeros(2*m*n + 5*n + 11*m*m + 8*m, float64)\n",
      "MemoryError: Unable to allocate 716. MiB for an array with shape (93788705,) and data type float64\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\users\\treva\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\treva\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\treva\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 1027, in fit\n",
      "    return self._fit(X, y, incremental=(self.warm_start and\n",
      "  File \"c:\\users\\treva\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 375, in _fit\n",
      "    self._fit_lbfgs(X, y, activations, deltas, coef_grads,\n",
      "  File \"c:\\users\\treva\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 461, in _fit_lbfgs\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"c:\\users\\treva\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\scipy\\optimize\\_minimize.py\", line 609, in minimize\n",
      "    return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"c:\\users\\treva\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\scipy\\optimize\\lbfgsb.py\", line 322, in _minimize_lbfgsb\n",
      "    wa = zeros(2*m*n + 5*n + 11*m*m + 8*m, float64)\n",
      "MemoryError: Unable to allocate 716. MiB for an array with shape (93788705,) and data type float64\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(MLPClassifier(max_iter=1000,solver='lbfgs', hidden_layer_sizes=(750,)),x_title,y,cv=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
